version: 1.0.8

endpoints:
  custom:
    # â”€â”€ Ollama direct (unchanged) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: "Ollama"
      apiKey: "ollama"
      baseURL: "http://ollama:11434/v1"
      models:
        default: ["mistral"]   # fallback if /tags fails
        fetch:   true          # Ollama exposes its own model list
      titleConvo: true
      titleModel: "current_model"
      summarize:  false
      modelDisplayLabel: "Ollama"

    # â”€â”€ LangGraph proxy (one provider, many models) â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: "LangGraph"
      apiKey: "proxy"                # dummy; proxy ignores it
      baseURL: "http://langchain:8082"   # LibreChat will append /v1/â€¦
      directEndpoint: false

      models:
        default: ["openchat"]        # placeholder (required field)
        fetch:   true                # LibreChat ðŸ‘‰ GET /v1/models

      titleConvo: true
      titleModel: "current_model"
      summarize:  false
      modelDisplayLabel: "LangGraph"
